"use strict";(self.webpackChunku_modeler_manual=self.webpackChunku_modeler_manual||[]).push([[9131],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>g});var r=a(67294);function n(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,r)}return a}function l(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){n(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function o(e,t){if(null==e)return{};var a,r,n=function(e,t){if(null==e)return{};var a,r,n={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||(n[a]=e[a]);return n}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)a=i[r],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(n[a]=e[a])}return n}var s=r.createContext({}),p=function(e){var t=r.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):l(l({},t),e)),a},u=function(e){var t=p(e.components);return r.createElement(s.Provider,{value:t},e.children)},m="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var a=e.components,n=e.mdxType,i=e.originalType,s=e.parentName,u=o(e,["components","mdxType","originalType","parentName"]),m=p(a),h=n,g=m["".concat(s,".").concat(h)]||m[h]||c[h]||i;return a?r.createElement(g,l(l({ref:t},u),{},{components:a})):r.createElement(g,l({ref:t},u))}));function g(e,t){var a=arguments,n=t&&t.mdxType;if("string"==typeof e||n){var i=a.length,l=new Array(i);l[0]=h;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o[m]="string"==typeof e?e:n,l[1]=o;for(var p=2;p<i;p++)l[p]=a[p];return r.createElement.apply(null,l)}return r.createElement.apply(null,a)}h.displayName="MDXCreateElement"},52991:(e,t,a)=>{a.d(t,{Z:()=>f});var r=a(67294),n=a(86010),i=a(53438),l=a(39960),o=a(13919),s=a(95999);const p="cardContainer_fWXF",u="cardTitle_rnsV",m="cardDescription_PWke";function c(e){let{href:t,children:a}=e;return r.createElement(l.Z,{href:t,className:(0,n.Z)("card padding--lg",p)},a)}function h(e){let{href:t,icon:a,title:i,description:l}=e;return r.createElement(c,{href:t},r.createElement("h2",{className:(0,n.Z)("text--truncate",u),title:i},a," ",i),l&&r.createElement("p",{className:(0,n.Z)("text--truncate",m),title:l},l))}function g(e){let{item:t}=e;const a=(0,i.Wl)(t);return a?r.createElement(h,{href:a,icon:"\ud83d\uddc3\ufe0f",title:t.label,description:t.description??(0,s.I)({message:"{count} items",id:"theme.docs.DocCard.categoryDescription",description:"The default description for a category card in the generated index about how many items this category includes"},{count:t.items.length})}):null}function d(e){let{item:t}=e;const a=(0,o.Z)(t.href)?"\ud83d\udcc4\ufe0f":"\ud83d\udd17",n=(0,i.xz)(t.docId??void 0);return r.createElement(h,{href:t.href,icon:a,title:t.label,description:t.description??n?.description})}function k(e){let{item:t}=e;switch(t.type){case"link":return r.createElement(d,{item:t});case"category":return r.createElement(g,{item:t});default:throw new Error(`unknown item type ${JSON.stringify(t)}`)}}function N(e){let{className:t}=e;const a=(0,i.jA)();return r.createElement(f,{items:a.items,className:t})}function f(e){const{items:t,className:a}=e;if(!t)return r.createElement(N,e);const l=(0,i.MN)(t);return r.createElement("section",{className:(0,n.Z)("row",a)},l.map(((e,t)=>r.createElement("article",{key:t,className:"col col--6 margin-bottom--lg"},r.createElement(k,{item:e})))))}},73663:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>p,contentTitle:()=>o,default:()=>c,frontMatter:()=>l,metadata:()=>s,toc:()=>u});var r=a(87462),n=(a(67294),a(3905)),i=a(52991);const l={slug:"/usage-guide/ai-texturing-properties",sidebar_position:1},o="AI Texturing Properties",s={unversionedId:"ai-texturing/usage-guide/ai-texturing-properties",id:"ai-texturing/usage-guide/ai-texturing-properties",title:"AI Texturing Properties",description:"UModeler X provides a wide range of settings for AI texturing, which are seamlessly integrated with the Stable Diffusion web UI through the API.",source:"@site/i18n/en/docusaurus-plugin-content-docs/current/ai-texturing/usage-guide/ai-texturing-properties.md",sourceDirName:"ai-texturing/usage-guide",slug:"/usage-guide/ai-texturing-properties",permalink:"/docs/usage-guide/ai-texturing-properties",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{slug:"/usage-guide/ai-texturing-properties",sidebar_position:1},sidebar:"docs",previous:{title:"Usage Guide",permalink:"/docs/usage-guide"},next:{title:"webui-user.bat command line parameters",permalink:"/docs/usage-guide/webui-user-bat-cli-parameters"}},p={},u=[{value:"<strong>Properties</strong>",id:"properties",level:2},{value:"ProjectionOnly",id:"projectiononly",level:3},{value:"Checkpoint",id:"checkpoint",level:3},{value:"Address",id:"address",level:3},{value:"Prompt",id:"prompt",level:3},{value:"NegativePrompt",id:"negativeprompt",level:3},{value:"CFGScale",id:"cfgscale",level:3},{value:"Sampler",id:"sampler",level:3},{value:"SamplingStep",id:"samplingstep",level:3},{value:"Restore Faces",id:"restore-faces",level:3},{value:"ImageMaxSize",id:"imagemaxsize",level:3},{value:"BatchCount",id:"batchcount",level:3},{value:"Use SceneMap (Img2Img)",id:"use-scenemap-img2img",level:3},{value:"Use Depth Control Net",id:"use-depth-control-net",level:3},{value:"Extra Control Net1",id:"extra-control-net1",level:3},{value:"Hires.fix",id:"hiresfix",level:3},{value:"Seed",id:"seed",level:3},{value:"Generate Forever",id:"generate-forever",level:3},{value:"Generate",id:"generate",level:3},{value:"Generate(Rect)",id:"generaterect",level:3},{value:"Custom Cameras",id:"custom-cameras",level:3},{value:"Result",id:"result",level:3},{value:"PromptHistory",id:"prompthistory",level:3}],m={toc:u};function c(e){let{components:t,...a}=e;return(0,n.kt)("wrapper",(0,r.Z)({},m,a,{components:t,mdxType:"MDXLayout"}),(0,n.kt)("h1",{id:"ai-texturing-properties"},"AI Texturing Properties"),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"UModeler X")," provides a wide range of settings for AI texturing, which are seamlessly integrated with the Stable Diffusion web UI through the API."),(0,n.kt)("p",null,"The ",(0,n.kt)("strong",{parentName:"p"},"AI texturing properties")," that can be viewed in ",(0,n.kt)("strong",{parentName:"p"},"UModeler X")," are primarily the most frequently used settings in the Stable Diffusion web UI. This allows users to quickly change settings and see the results without having to go back to the web UI."),(0,n.kt)("p",null,"Settings adjusted in the Stable Diffusion web UI are automatically reflected in UModeler X, even if the desired property is not available in ",(0,n.kt)("strong",{parentName:"p"},"UModeler X"),"."),(0,n.kt)("hr",null),(0,n.kt)("h2",{id:"properties"},(0,n.kt)("strong",{parentName:"h2"},"Properties")),(0,n.kt)("h3",{id:"projectiononly"},"ProjectionOnly"),(0,n.kt)("p",null,"This property generates a texture of the current state of the model ",(0,n.kt)("strong",{parentName:"p"},"without using AI texturing"),"."),(0,n.kt)("p",null,"Useful for previewing the camera state or current DepthMap representation of the model using the various generate buttons before applying AI texturing."),(0,n.kt)("h3",{id:"checkpoint"},"Checkpoint"),(0,n.kt)("p",null,"This setting selects the checkpoint to use for AI texturing."),(0,n.kt)("h3",{id:"address"},"Address"),(0,n.kt)("p",null,"This is the address to access the ",(0,n.kt)("strong",{parentName:"p"},"Stable Diffusion web UI"),". The default setting is ",(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("a",{parentName:"strong",href:"http://127.0.0.1:7860/"},"http://127.0.0.1:7860/")),", and in most cases you will not need to change this value."),(0,n.kt)("h3",{id:"prompt"},"Prompt"),(0,n.kt)("p",null,"This is a text field that specifies ",(0,n.kt)("strong",{parentName:"p"},"what you want to see")," when generating the texture."),(0,n.kt)("h3",{id:"negativeprompt"},"NegativePrompt"),(0,n.kt)("p",null,"A text field to specify what you ",(0,n.kt)("strong",{parentName:"p"},"want to exclude or modify")," from the texture that will be generated. In general, it is recommended that you use the ",(0,n.kt)("strong",{parentName:"p"},"Negative Embedding")," to fill in this part of the text rather than writing it yourself."),(0,n.kt)("p",null,"Below is a guide to setting up ",(0,n.kt)("strong",{parentName:"p"},"Negative Embedding"),"."),(0,n.kt)(i.Z,{items:[{type:"link",label:"Negative Embedding",href:"/docs/usage-guide/negative-embedding"}],mdxType:"DocCardList"}),(0,n.kt)("h3",{id:"cfgscale"},"CFGScale"),(0,n.kt)("p",null,"The ",(0,n.kt)("strong",{parentName:"p"},"CFG Scale (Classifier-Free Guidance Scale)")," is a property that controls how closely the generated image follows the prompt."),(0,n.kt)("p",null,(0,n.kt)("strong",{parentName:"p"},"Higher values of CFG Scale")," generate images that are more faithful to the prompt, but at the expense of image quality."),(0,n.kt)("p",null,"Conversely, a ",(0,n.kt)("strong",{parentName:"p"},"lower CFG Scale value")," will result in an image that follows the prompt less closely, but the image quality is likely to be higher."),(0,n.kt)("admonition",{title:"Suggested Values",type:"tip"},(0,n.kt)("h2",{parentName:"admonition",id:"cfgscale-1"},"CFGScale"),(0,n.kt)("p",{parentName:"admonition"},"We typically recommend setting it to a value between ",(0,n.kt)("strong",{parentName:"p"},"7 and 9"),".")),(0,n.kt)("h3",{id:"sampler"},"Sampler"),(0,n.kt)("p",null,"This setting determines the probabilistic method used to generate the texture. Each sampler handles the random parts of the texture differently, making a small difference in the final result."),(0,n.kt)("p",null,"Simply put, the ",(0,n.kt)("strong",{parentName:"p"},"Sampler")," is the setting that determines how randomness is handled during texture generation."),(0,n.kt)("admonition",{title:"Recommended Sampling Method",type:"tip"},(0,n.kt)("h2",{parentName:"admonition",id:"sampler-1"},"Sampler"),(0,n.kt)("p",{parentName:"admonition"},"We mainly recommend ",(0,n.kt)("strong",{parentName:"p"},"Euler a, DPM++ SDE and DPM2 karras"),".")),(0,n.kt)("h3",{id:"samplingstep"},"SamplingStep"),(0,n.kt)("p",null,"This setting determines how much sampling is done during the texture generation process. The higher the number of sampling steps, the higher quality textures can be generated, but the longer the texture generation time."),(0,n.kt)("admonition",{title:"Recommended Values",type:"tip"},(0,n.kt)("h2",{parentName:"admonition",id:"samplingstep-1"},"SamplingStep"),(0,n.kt)("p",{parentName:"admonition"},"Generally, we recommend a SamplingStep value of ",(0,n.kt)("strong",{parentName:"p"},"20 to 25"),".")),(0,n.kt)("h3",{id:"restore-faces"},"Restore Faces"),(0,n.kt)("p",null,"This property is used when faces or eye parts are generated incorrectly. We recommend enabling this when facial expressions are misrepresented, especially in realistic art styles."),(0,n.kt)("h3",{id:"imagemaxsize"},"ImageMaxSize"),(0,n.kt)("p",null,"This property sets the ",(0,n.kt)("strong",{parentName:"p"},"size of the generated texture"),"."),(0,n.kt)("h3",{id:"batchcount"},"BatchCount"),(0,n.kt)("p",null,"Property that sets the ",(0,n.kt)("strong",{parentName:"p"},"total number of images to be generated in a row")," in a single generation pass."),(0,n.kt)("h3",{id:"use-scenemap-img2img"},"Use SceneMap (Img2Img)"),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"Layer as Inpaint Mask")),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This property applies AI texturing only to areas that are painted with a ",(0,n.kt)("strong",{parentName:"li"},"Brush")," on the ",(0,n.kt)("strong",{parentName:"li"},"Paint Layer"),". When painting, it is recommended to use a color that is primarily the color you want to represent, or a color that is similar to the surrounding colors."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("p",{parentName:"li"},(0,n.kt)("strong",{parentName:"p"},"Denoising strength")),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This property determines how much the painted area is allowed to change in content. Closer to 0, there is no change, and closer to 1, the content changes significantly.")))),(0,n.kt)("h3",{id:"use-depth-control-net"},"Use Depth Control Net"),(0,n.kt)("p",null,"A setting that enables the ",(0,n.kt)("strong",{parentName:"p"},"Depth model")," of the ",(0,n.kt)("strong",{parentName:"p"},"ControlNet"),". The ",(0,n.kt)("strong",{parentName:"p"},"Depth")," data represents points ",(0,n.kt)("strong",{parentName:"p"},"closer to the viewpoint")," in white and points ",(0,n.kt)("strong",{parentName:"p"},"farther away")," in black.\n",(0,n.kt)("strong",{parentName:"p"},"UModeler X's AI Texturing")," converts the depth of the model into an image and applies it to the Depth model based on the current ",(0,n.kt)("strong",{parentName:"p"},"scene view"),"."),(0,n.kt)("p",null,"This setting can be utilized to generate more accurate textures that take into account the model's ",(0,n.kt)("strong",{parentName:"p"},"three-dimensional shape"),"."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"ControlnetModel"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Option to select the Depth model to use. There are multiple versions of the same model, so choose the one you want."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Weight"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"A slider that controls the influence of the Depth model. Values closer to 0 have less influence, while higher values have more influence."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Mode"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"A property that sets the emphasis between the ",(0,n.kt)("strong",{parentName:"li"},"Prompt")," and ",(0,n.kt)("strong",{parentName:"li"},"ControlNet"),".",(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Balanced:")," The prompt and ControlNet have equal importance."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"My prompt is more important:")," The prompt is more important."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"ControlNet is more important:")," The impact of the Depth model in the ControlNet is more important."))))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"NearDistanceMargin"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Option to set the near distance margin."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"FarDistanceMargin"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Options to set the margin for the far distance.")))),(0,n.kt)("h3",{id:"extra-control-net1"},"Extra Control Net1"),(0,n.kt)("p",null,"This setting is enabled when you want to use ",(0,n.kt)("strong",{parentName:"p"},"an additional ControlNet model")," in addition to the default ControlNet model."),(0,n.kt)("p",null,"You can apply two or more ControlNet models in parallel or in chains to get an AI texturing result that ",(0,n.kt)("strong",{parentName:"p"},"combines the best of each model"),"."),(0,n.kt)("h3",{id:"hiresfix"},"Hires.fix"),(0,n.kt)("p",null,"A property that enables ",(0,n.kt)("strong",{parentName:"p"},"upscaling")," to quickly generate textures that are ",(0,n.kt)("strong",{parentName:"p"},"larger than the set size"),"."),(0,n.kt)("p",null,"This feature allows you to generate large textures in a relatively short amount of time, but it can take too long to generate them."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Upscaler"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This property selects the upscaling method used when upscaling the texture."),(0,n.kt)("li",{parentName:"ul"},"The following are recommended: ",(0,n.kt)("strong",{parentName:"li"},"Latent, ScuNET GAN, R-ESRGAN_4x, R-ESRGAN_4x+Animated 6B"),"."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Upscale by"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This property sets the scale factor to multiply the set texture size by."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Denoising Strength"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This property determines how much the texture generated during the upscaling process is allowed to change in content. Closer to 0, there will be no change, while closer to 1, the content of the texture will change significantly."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Hires steps"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This property sets how many times the texture upscaling is repeated. Higher values will result in better quality, but may result in longer generation times.")))),(0,n.kt)("h3",{id:"seed"},"Seed"),(0,n.kt)("p",null,"A ",(0,n.kt)("strong",{parentName:"p"},"unique number")," that plays an important role in texture generation."),(0,n.kt)("p",null,"Using the same prompt, settings, and Seed value will always generate the same image. The ",(0,n.kt)("strong",{parentName:"p"},"default value is -1"),", which generates a randomized image each time."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Shuffle"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Button to set the Seed value to random. When ",(0,n.kt)("strong",{parentName:"li"},(0,n.kt)("inlineCode",{parentName:"strong"},"Click")),", the Seed value is automatically set to ",(0,n.kt)("strong",{parentName:"li"},"-1"),"."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Last Seed"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This function allows you to retrieve the Seed value of the most recently generated Texture.")))),(0,n.kt)("h3",{id:"generate-forever"},"Generate Forever"),(0,n.kt)("p",null,"If checked to enable, this property will continue to generate textures until unchecked."),(0,n.kt)("h3",{id:"generate"},"Generate"),(0,n.kt)("p",null,"Button to proceed with texture generation."),(0,n.kt)("h3",{id:"generaterect"},"Generate(Rect)"),(0,n.kt)("p",null,"This button starts texture generation for a rectangular area created by ",(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("inlineCode",{parentName:"strong"},"Click and Drag"))," in the scene."),(0,n.kt)("h3",{id:"custom-cameras"},"Custom Cameras"),(0,n.kt)("p",null,"This property is used to generate textures based on pre-placed cameras. Select the desired camera by ",(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("inlineCode",{parentName:"strong"},"Click"))," the slot next to the property, and that camera will be used as the basis."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"R")," : Button to ",(0,n.kt)("strong",{parentName:"li"},"reset")," all set cameras."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"+"),": Button to ",(0,n.kt)("strong",{parentName:"li"},"add")," a camera slot."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"-")," : Button to ",(0,n.kt)("strong",{parentName:"li"},"delete")," a camera slot. The lowest camera will be deleted first."),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Generate (Custom Camera)"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This button generates textures in succession based on the number of cameras set up."),(0,n.kt)("li",{parentName:"ul"},"For example, if you have two cameras set up, the texture will be generated twice in a row."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Generate (All in One)"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"Unlike the ",(0,n.kt)("strong",{parentName:"li"},"Generate (Custom Camera) button"),", this button generates one texture at a time, taking into account the orientation of all set cameras."),(0,n.kt)("li",{parentName:"ul"},"If the cameras are positioned so that the image areas of the model overlap, the generated textures may also overlap, so be careful.")))),(0,n.kt)("h3",{id:"result"},"Result"),(0,n.kt)("p",null,"An at-a-glance view of the generated textures and the various features associated with them."),(0,n.kt)("ul",null,(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Rescan"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"A button that brings up all of the textures generated for the currently active model."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Rescan All"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This button loads all textures created within the current project in bulk."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Apply Texture"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This button applies the selected texture to the model and displays it on the screen."))),(0,n.kt)("li",{parentName:"ul"},(0,n.kt)("strong",{parentName:"li"},"Restore Saved Camera Transform"),(0,n.kt)("ul",{parentName:"li"},(0,n.kt)("li",{parentName:"ul"},"This button moves and rotates the scene to the camera view when the selected resulting texture was generated.")))),(0,n.kt)("h3",{id:"prompthistory"},"PromptHistory"),(0,n.kt)("p",null,"Allows you to view the history of prompts used. You can bring up the contents of the ",(0,n.kt)("strong",{parentName:"p"},"Prompt")," and ",(0,n.kt)("strong",{parentName:"p"},"NegativePrompt")," by ",(0,n.kt)("strong",{parentName:"p"},(0,n.kt)("inlineCode",{parentName:"strong"},"Click"))," the ",(0,n.kt)("strong",{parentName:"p"},"Apply button")," next to the desired prompt history."))}c.isMDXComponent=!0}}]);